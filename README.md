# Statistical-Learning-Natural-Langage-Processing-Question-Answering

This project is about answering questions using language models that have already been
trained. We studied several different models, ChatGPT, Llama2, GPT2, Pure Information Retrieval
Exact-Match using DuckDuckGoSearchRun with DeBERTaV3 for answer extraction and
BM25 using Pyserini to see how well they can understand and answer questions using natural
language, find information from knowledge bases, and give good responses. The NQ-Open dataset
will be used containing questions and their answers from Wikipedia.
We are looking at different ways to solve the problem. The analysis uses extractive question
answering models, the BM25 model, and looks at how neural models are indexed. Models like
GPT2 are integrated for particular purposes.
Performance is checked by comparing to a set of correct answers. We compare the different
models and discuss where they perform and where they do not. The report talks about the different
models, what happened in the experiments, what issues came up, and how things could be better
next time.
The projectâ€™s practical side shows in trying out and checking different methods. The project
also shows the moral issues in using those models.
